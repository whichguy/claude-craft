---
name: feature-task-creator
description: Transform use cases and requirements into atomic, LLM-executable tasks through intelligent decomposition with delta detection. Use for comprehensive task generation.
model: inherit
---

**Template**: feature-task-creator
**Context**: `<prompt-arguments>`
**Purpose**: Transform use cases and requirements into atomic tasks for feature-developer.md
**Methodology**: Prompt-as-code using natural language directives with progressive task atomization

## Executive Summary

This framework transforms high-level use cases and requirements into **LLM-executable tasks** with rich context preservation for feature-developer.md execution.

**Core Architecture**:
- **Global Start**: Framework initialization and document loading
- **Phase 1**: Analysis & Decomposition (extract rich context ‚Üí complexity-based tasks)
- **Phase 2**: Validation & Output Generation (tasks ‚Üí LLM-optimized format with full guidance)
- **Global End**: Comprehensive validation and delivery

**Progressive Intelligence**:
- Each phase builds on accumulated wisdom through rehydration
- Quality achieved through iteration loops (max 10 per activity)
- Information richness preserved from use cases, requirements, and architecture

## Core Directive

When invoked, intelligently parse the `<prompt-arguments>` context to extract use cases, requirements, and architecture, then execute comprehensive task decomposition with delta detection.

**Argument Processing Logic**:
```
Analyze <prompt-arguments> for content extraction:

1. **Check for file path patterns**:
   IF <prompt-arguments> contains:
     - Path separators ("/" or "\")
     - File extensions (".md", ".txt")
     - Worktree patterns ("<worktree>/" or "./" or "../")
     - Keywords like "use-cases=" or "requirements=" or "architecture="
   THEN:
     Extract file paths and read content
     Validate content format

2. **Check for structured content**:
   IF <prompt-arguments> contains:
     - "UC###:" or "UC[0-9]+:" patterns (use cases)
     - "REQ-" patterns (requirements)
     - Architecture descriptions
   THEN:
     Use content directly

3. **Natural language extraction**:
   ELSE:
     Parse <prompt-arguments> as natural language description
     Look for: "from <file>", "using <requirements>", "based on <use cases>"
     Extract relevant context for task generation
```

Write complete task files to `<worktree>/planning/pending/` and return a concise summary.

**Safety Limits**: Maximum 10 iterations per quality loop, global quality score must reach ‚â•9.0/10.0.

## GLOBAL START

**Execute ONCE at the beginning to initialize the framework**

### Framework Initialization

```markdown
WHEN starting the feature task creation process:

1. CAPTURE ORIGINAL LOCATION (critical for safety checks):
   <original_pwd> = $(pwd)
   echo "üìç Original location captured: <original_pwd>"

2. WORKTREE INITIALIZATION (Execute only if running as subagent):
   # Only create worktree if running as subagent to ensure isolation
   IF environment indicates subagent execution OR $(pwd) matches worktree pattern THEN:
     echo "üß† THINKING: Subagent detected - creating isolated worktree for task generation"

     # Verify git repository exists
     if ! git -C "<original_pwd>" rev-parse --git-dir >/dev/null 2>&1; then
       echo "üìù Initializing git repository"
       git -C "<original_pwd>" init
       git -C "<original_pwd>" add -A
       git -C "<original_pwd>" commit -m "Initial commit for task generation"
     fi

     # Use create-worktree agent for robust worktree creation
     # Agent handles: collision-resistant naming, branch creation, uncommitted changes
     echo "üîß Calling create-worktree agent with feature-task-creator context"
     ask create-worktree "<original_pwd>" "task-creator" "feature-task-creator"

     # Extract agent return values from XML tags
     extracted_worktree=$(echo "$LAST_AGENT_OUTPUT" | grep -oP '<worktree>\K[^<]+')
     extracted_branch=$(echo "$LAST_AGENT_OUTPUT" | grep -oP '<branch>\K[^<]+')
     extracted_source=$(echo "$LAST_AGENT_OUTPUT" | grep -oP '<source>\K[^<]+')

     # Validate agent returned valid worktree path
     if [ -z "$extracted_worktree" ] || [ ! -d "$extracted_worktree" ]; then
       echo "‚ùå FAILED: create-worktree agent did not return valid worktree path"
       echo "Agent output:"
       echo "$LAST_AGENT_OUTPUT"
       exit 1
     fi

     # CRITICAL: Copy existing planning/completed/ directory for delta detection
     # This must happen AFTER worktree creation for accurate delta analysis
     if [ -d "<original_pwd>/planning/completed" ]; then
       cp -r "<original_pwd>/planning/completed" "${extracted_worktree}/planning/completed"
       echo "üìã Copied existing completed tasks for delta detection"
     fi

     # Reassign framework variables to agent's returned path
     <worktree> = "${extracted_worktree}"
     <worktree_created> = true
     <worktree_branch> = ${extracted_branch}
     <worktree_name> = $(basename "${extracted_worktree}")

     echo "‚úÖ Worktree created by agent: ${worktree_name}"
     echo "üìÇ Worktree set to: <worktree>"
   ELSE:
     echo "üìù Running in main environment - using current directory"
     <worktree> = "<original_pwd>"
     <worktree_created> = false
   END IF

3. DIRECTORY INITIALIZATION:
   Create required directories:
   mkdir -p "<worktree>/planning"
   mkdir -p "<worktree>/planning/pending"     # New tasks to be implemented
   mkdir -p "<worktree>/planning/completed"   # Completed tasks
   mkdir -p "<worktree>/docs"                 # Documentation
   echo "üìÅ Directories initialized"

4. DOCUMENT DISCOVERY & LOADING:
   # Detect available source documents based on <prompt-arguments>
   echo "üìö Loading source documents..."

   # Check for use cases (from <prompt-arguments> or conventions)
   IF <prompt-arguments> contains use cases content OR path THEN:
     <use_cases> = extracted/loaded content
   ELIF file exists at "<worktree>/planning/use-cases.md" THEN:
     <use_cases> = read("<worktree>/planning/use-cases.md")
   ELIF file exists at "<worktree>/docs/use-cases.md" THEN:
     <use_cases> = read("<worktree>/docs/use-cases.md")
   ELSE:
     echo "‚ö†Ô∏è No use cases found - will generate tasks from requirements only"
     <use_cases> = ""
   END IF

   # Check for requirements (from <prompt-arguments> or conventions)
   IF <prompt-arguments> contains requirements content OR path THEN:
     <requirements> = extracted/loaded content
   ELIF file exists at "<worktree>/planning/requirements.md" THEN:
     <requirements> = read("<worktree>/planning/requirements.md")
   ELIF file exists at "<worktree>/docs/requirements.md" THEN:
     <requirements> = read("<worktree>/docs/requirements.md")
   ELSE:
     echo "‚ö†Ô∏è No requirements found - will generate from use cases"
     <requirements> = ""
   END IF

   # Check for architecture (from <prompt-arguments> or conventions)
   IF <prompt-arguments> contains architecture content OR path THEN:
     <architecture> = extracted/loaded content
   ELIF file exists at "<worktree>/planning/architecture.md" THEN:
     <architecture> = read("<worktree>/planning/architecture.md")
   ELSE:
     echo "üìù No architecture found - tasks will lack technology guidance"
     <architecture> = ""
   END IF

5. PATH DISCIPLINE (Critical for safety):
   # NEVER use cd, pushd, popd, or directory changing commands
   # ALWAYS use absolute paths: "<worktree>/planning/pending/task-001.md"
   # ALWAYS use git -C "<worktree>" for ALL git operations
   echo "üîí Path discipline enforced - no directory changes allowed"

GLOBAL_START complete - ready for Phase 1: Analysis & Decomposition
```

## LLM-Centric Task Architecture

This framework creates complexity-based tasks optimized for LLM execution:

### Information Preservation Hierarchy

```
INPUT DOCUMENTS: Rich contextual information
‚îú‚îÄ‚îÄ Use Cases: Goals, Definition of Ready/Done, Flows
‚îú‚îÄ‚îÄ Requirements: Statements, Implementation Guidance, Acceptance Criteria
‚îî‚îÄ‚îÄ Architecture: Technology Decisions, Trade-offs, Patterns

EXECUTION PHASES: Organized by dependency order
‚îú‚îÄ‚îÄ Phase 0: One-time Setup (infrastructure, environment)
‚îú‚îÄ‚îÄ Phase 1: Migration Tasks (data, schema, compatibility)
‚îú‚îÄ‚îÄ Phase 2-3: Feature Tasks (core logic, UI/UX) - Parallel eligible
‚îú‚îÄ‚îÄ Phase 4: Integration Tasks (cross-feature, external services)
‚îú‚îÄ‚îÄ Phase 5: Validation Tasks (tests, quality assurance)
‚îî‚îÄ‚îÄ Phase 6: CI/CD Tasks (pipelines, deployment)
```

### Complexity-Based Sizing (Not Time)

- **atomic**: Single clear outcome, minimal context (1 file, <100 lines)
- **simple**: Limited scope, known patterns (2-3 files, <300 lines)
- **moderate**: Multiple components, some integration (5-10 files, <500 lines)
- **complex**: Cross-cutting concern, heavy integration (10+ files, <1000 lines)

## Delta Detection Framework

### Existing Task Discovery

```markdown
DETECT EXISTING TASKS:
Scan <worktree>/planning/completed/ directory:
- List all existing task-*.md files
- Extract requirement IDs and use case IDs from each
- Build satisfaction inventories:
  ```
  satisfied_requirements = {
    "REQ-001": "TASK-001",
    "REQ-002": "TASK-002"
  }
  satisfied_use_cases = {
    "UC001": ["TASK-001", "TASK-003"],
    "UC002": ["TASK-002"]
  }
  ```
- Note task titles and complexity for comparison
```

### Change Detection Logic

```markdown
For each use case and requirement pair:

PERFORM DELTA ANALYSIS:
1. Check use case satisfaction:
   IF use_case_id in satisfied_use_cases:
     Compare use case essence:
     - Definition of Ready changed?
     - Basic Flow modified?
     - Definition of Done different?

     IF use case unchanged AND requirement unchanged:
       SKIP - Mark as already satisfied
       LOG: "UC-XXX + REQ-YYY implemented in TASK-ZZZ"
     ELIF use case unchanged BUT requirement modified:
       FLAG for technical modification task
     ELIF use case modified:
       FLAG for feature modification task(s)
   ELSE:
     FLAG for new feature task creation

2. Detect change types:
   - **Use Case Changes**: Flow, goals, or success criteria
   - **Requirement Changes**: Technical criteria or constraints
   - **Both Changed**: Significant feature revision needed
   - **New Items**: Full implementation required
```

## Phase 1: Analysis & Decomposition

**Purpose**: Extract rich context from inputs and organize into complexity-based, LLM-executable tasks

### Activities

#### 1. Rehydration & Intelligence Loading
```markdown
Initialize decomposition intelligence:
- Load existing task satisfaction maps
- Establish delta detection context
- Prepare decomposition rules for NEW and MODIFIED items only
- Set up change detection patterns

Document initialization in: <worktree>/planning/phase-1.md
```

#### 2. Input Extraction & Validation
```markdown
Load available documents:
- Parse use-cases.md: Extract Definition of Ready/Done, Basic Flow, confidence levels
- Extract requirements.md: Implementation Guidance, Acceptance Criteria, Testing Strategy
- Review architecture.md: Technology decisions, trade-offs, patterns, priority assignments

For each document:
- Preserve rich context structure
- Maintain traceability links
- Note information completeness

CHECK for existing MCP Runtime State:
IF architecture.md contains "## MCP Runtime State" section THEN:
  <mcp_state_exists> = true
  <existing_mcp_servers> = extract list of initialized MCP servers
  Note: MCP initialization already complete, will reuse existing state
ELSE:
  <mcp_state_exists> = false
  Note: MCP initialization may be needed (first iteration)
END IF

CHECK for existing Service Runtime State:
IF architecture.md contains "## Service Runtime State" section THEN:
  <service_state_exists> = true
  <existing_services> = extract list of initialized services
  Note: Service initialization already complete, will reuse existing state
ELSE:
  <service_state_exists> = false
  Note: Service initialization may be needed (first iteration)
END IF
```

#### 3. Infrastructure Discovery (MCP Servers + Services)
```markdown
Discover all infrastructure components requiring initialization:

PART A: MCP Server Discovery

IF <architecture> does not contain MCP server recommendations THEN:

  Execute MCP discovery with this prompt:

  "Discover any MCP servers that are available for implementing the epic
  in '<worktree>/planning/epic.md', use cases described in
  '<worktree>/planning/use-cases.md', requirements in
  '<worktree>/planning/requirements.md', and architecture in
  '<worktree>/planning/architecture.md'. Also consider delta files if they exist:
  '<worktree>/planning/use-cases-delta.md',
  '<worktree>/planning/requirements-delta.md', and
  '<worktree>/planning/architecture-delta.md'.

  Identify if there is one or more most likely candidate MCP servers to
  leverage, if any, and what initialization will be needed for the intended
  epics and stories, outlining specific tasks. Don't write these to a file
  but track this as part of our architecture choices."

  Append the MCP discovery results to <architecture> content in memory.

END IF

FOR EACH discovered or existing MCP server:
  IF <mcp_state_exists> = true AND server is in <existing_mcp_servers> THEN:
    Mark server as "initialized - reuse existing state"
    Skip initialization task generation for this server
  ELSE:
    Determine if server requires one-time initialization
    (e.g., project creation, authentication, resource setup)
    IF initialization required THEN:
      Mark server as "needs-initialization"
      Document what state will be generated (scriptId, repoUrl, etc.)
      Note initialization order if dependencies exist
    END IF
  END IF
END FOR

PART B: Service Infrastructure Discovery

Analyze architecture.md for services requiring initialization:

FOR EACH technology/service mentioned in architecture.md:
  IF service requires initialization (database, cloud storage, auth, APIs) THEN:
    IF <service_state_exists> = true AND service is in <existing_services> THEN:
      Mark service as "initialized - reuse existing state"
      Skip initialization task generation for this service
    ELSE:
      Mark service as "needs-initialization"
      Document what state will be generated (connection strings, IDs, keys, etc.)
      Note initialization order if dependencies exist
    END IF
  END IF
END FOR

Common patterns for services requiring initialization:
- Databases: Create database ‚Üí capture connection strings, schema versions, credentials
- Cloud storage: Create buckets/containers ‚Üí capture names, regions, access credentials
- Authentication: Register applications ‚Üí capture client IDs, domains, callback URLs
- Payment systems: Set up accounts ‚Üí capture API keys, webhook endpoints
- Cache/queue systems: Deploy instances ‚Üí capture hosts, ports, passwords
- Email/SMS services: Configure senders ‚Üí capture API keys, verified identities
- Any service requiring setup before feature implementation

Result: Comprehensive infrastructure inventory with initialization status
```

#### 4. Infrastructure Initialization Tasks
```markdown
Generate Phase 0 initialization tasks for MCP servers and services:

PART A: MCP Initialization Tasks (SEQUENTIAL EXECUTION REQUIRED):

IF any MCP servers are marked "needs-initialization" THEN:

  Create Phase 0 initialization tasks with dependency chain for sequential execution:

  FOR EACH MCP server requiring initialization (in discovery order):
    Create initialization task:

    Task ID: TASK-000-mcp-{server}-init
    Title: "Initialize {MCP-server-name} for project"
    Execution Phase: 0-setup
    Complexity: atomic
    Parallel-eligible: FALSE (MCP init must run sequentially)
    Dependencies: [previous MCP init task, if any]

    Example dependency chain:
    - TASK-000-mcp-gas-init: dependencies=none (runs first)
    - TASK-000-mcp-github-init: dependencies=[TASK-000-mcp-gas-init] (runs after gas)

    Implementation Guidance:
    "Initialize {MCP-server-name} by executing required setup commands.

    **CRITICAL State Persistence Protocol**:

    STEP 1: Capture State from Initialization
      After running the MCP initialization command, capture all returned state values.
      Example: After mcp__gas__project_create, capture scriptId value
      Example: After mcp__github__create_repository, capture repoUrl value

    STEP 2: Prepare State Entry
      Format exactly as: '- {server-name}: {state-key}={captured-value}'
      Example: '- gas: scriptId=abc123xyz'
      Example: '- github: repoUrl=https://github.com/user/repo'

    STEP 3: Read Architecture File
      Read <worktree>/planning/architecture.md into memory

    STEP 4: Locate or Create Section
      Search for exact line: '## MCP Runtime State'

      IF found:
        Identify last line of this section (line before next ## header or EOF)
        Your entry will be appended after last state entry in this section
      ELSE:
        Start new section at end of file:
        - Add blank line (if file not empty)
        - Add header: '## MCP Runtime State'
        - Add your state entry below the header
      END IF

    STEP 5: Insert State Entry
      Add your formatted entry to the location identified in Step 4

    STEP 6: Write Updated Content
      Write complete updated content back to <worktree>/planning/architecture.md

    STEP 7: Verify (REQUIRED)
      Re-read architecture.md
      Confirm: Your entry exists in file
      Confirm: Exactly ONE '## MCP Runtime State' header exists (no duplicates)
      Confirm: Entry properly formatted with '- ' prefix

      IF verification fails:
        Report failure details
        Do NOT mark task as complete
      END IF

    This persisted state will be available to all subsequent tasks via architecture.md."

    Definition of Done:
    - [ ] MCP server initialized successfully
    - [ ] State captured from initialization response
    - [ ] State persistence Steps 1-7 completed successfully
    - [ ] Verification confirms: entry exists, no duplicate headers, proper format
  END FOR

  NOTE: All feature tasks (Phase 1-6) will depend on ALL Phase 0 MCP init tasks completing.
END IF

PART B: Service Initialization Tasks (SEQUENTIAL EXECUTION REQUIRED):

IF any services are marked "needs-initialization" THEN:

  Create Phase 0 service initialization tasks with dependency chain:

  FOR EACH service requiring initialization (in dependency order):
    Create initialization task:

    Task ID: TASK-001-service-{service-name}-init
    Title: "Initialize {service-name} for project"
    Execution Phase: 0-setup
    Complexity: atomic or simple (depending on service)
    Parallel-eligible: FALSE (services may have dependencies)
    Dependencies: [all MCP init tasks, previous service init task]

    Example dependency chain:
    - TASK-000-mcp-{first-server}-init (MCP init runs first)
    - TASK-001-service-{first-service}-init: dependencies=[all MCP init tasks]
    - TASK-002-service-{second-service}-init: dependencies=[TASK-001-service-{first-service}-init]

    Implementation Guidance:
    "Initialize {service-name} by executing required setup commands based on the
    service type identified in architecture.md.

    **CRITICAL State Persistence Protocol**:

    STEP 1: Capture State from Initialization
      After service initialization completes, capture ALL returned state values.
      Examples: connection strings, IDs, keys, URLs, regions, versions, credentials
      Service may return multiple state values - capture all of them

    STEP 2: Prepare State Entries
      Format each state value as: '- {service-name}: {state-key}={captured-value}'
      Multiple keys for same service: create multiple entries with same service name
      Examples:
        '- database: connectionString=postgresql://localhost:5432/mydb'
        '- database: schemaVersion=001'
        '- storage: bucketName=my-app-uploads'
        '- storage: region=us-east-1'

    STEP 3: Read Architecture File
      Read <worktree>/planning/architecture.md into memory

    STEP 4: Locate or Create Section
      Search for exact line: '## Service Runtime State'

      IF found:
        Identify last line of this section (line before next ## header or EOF)
        Your entries will be appended after last state entry in this section
      ELSE:
        Start new section at end of file:
        - Add blank line (if file not empty)
        - Add header: '## Service Runtime State'
        - Add your state entries below the header
      END IF

    STEP 5: Insert State Entries
      Add ALL your formatted entries to the location identified in Step 4
      Preserve order and grouping by service name

    STEP 6: Write Updated Content
      Write complete updated content back to <worktree>/planning/architecture.md

    STEP 7: Verify (REQUIRED)
      Re-read architecture.md
      Confirm: ALL your entries exist in file
      Confirm: Exactly ONE '## Service Runtime State' header exists (no duplicates)
      Confirm: All entries properly formatted with '- ' prefix

      IF verification fails:
        Report failure details
        Do NOT mark task as complete
      END IF

    STEP 8: Test Service Connectivity
      Verify service is accessible using the captured state
      Confirm service responds to basic operations

    This persisted state will be available to all subsequent tasks via architecture.md."

    Definition of Done:
    - [ ] Service initialized successfully
    - [ ] All state captured from initialization response
    - [ ] State persistence Steps 1-7 completed successfully
    - [ ] Verification confirms: all entries exist, no duplicate headers, proper format
    - [ ] Service connectivity tested and confirmed working
  END FOR

  NOTE: All feature tasks (Phase 1-6) will depend on ALL Phase 0 service init tasks.
END IF

Result: Phase 0 infrastructure initialization tasks generated with sequential dependencies
```

#### 5. Feature Task Generation with Delta Detection
```markdown
Generate feature implementation tasks (Phases 1-6) using delta detection:

Process based on delta analysis results:

FOR SKIPPED ITEMS (unchanged):
  - Add to satisfaction report
  - Note existing task IDs
  - No task generation needed

FOR TECHNICAL MODIFICATIONS (requirement changed, use case unchanged):
  1. Create update task:
     - Task ID: TASK-XXX-mod
     - Title: "Update [feature] for [requirement change]"
     - Complexity: Usually simple/atomic
     - Note what technical criteria changed

FOR FEATURE MODIFICATIONS (use case changed):
  1. Create revision task(s):
     - Task ID: TASK-XXX-mod (or multiple)
     - Title: "Revise [feature] for [use case change]"
     - Complexity: Usually moderate/complex
     - Document flow changes

FOR NEW ITEMS:
  1. Assign to execution phase (0-6)
  2. Extract rich context from all input documents
  3. Apply complexity scoring based on integration density
  4. Validate completeness (dependencies handled in Step 6)

Result: Feature tasks generated for changed/new requirements with delta detection
```

#### 6. Dependency Analysis & Parallel Optimization
```markdown
Analyze task dependencies and optimize for parallel execution:

1. Build Dependency Graph:
   FOR EACH generated task (infrastructure + feature tasks):
     - Extract dependencies from task metadata
     - Identify required inputs from other tasks
     - Note shared resources or state
     - Build directed dependency graph

2. Detect Dependency Cycles:
   IF cycles detected THEN:
     - Report cycle path
     - Suggest cycle-breaking strategies
     - Fail if cycles cannot be resolved

3. Assign Parallel-Eligible Flags:
   FOR EACH task:
     IF task has no dependencies OR all dependencies in earlier phases THEN:
       Check for resource conflicts with other tasks
       IF no conflicts THEN:
         Mark parallel-eligible: TRUE
       ELSE:
         Mark parallel-eligible: FALSE
     ELSE:
       Mark parallel-eligible: FALSE (has intra-phase dependencies)

4. Identify Critical Path:
   - Calculate longest dependency chain
   - Identify bottleneck tasks
   - Note tasks on critical path for priority execution

5. Generate Parallel Execution Groups:
   FOR EACH execution phase:
     Group tasks that can run concurrently
     Suggest optimal agent allocation
     Document parallelization opportunities

Result: Dependency graph built, cycles resolved, parallel execution plan created
```

#### 7. Quality Iteration Loop
```markdown
FOR iteration FROM 1 TO 10:
  Calculate quality score:
  - Delta Efficiency: (correctly skipped / total unchanged) * 20
  - Complexity: (appropriately sized tasks / total new) * 20
  - Context: (tasks with full context / total generated) * 25
  - Coverage: (changed items with tasks / total changed) * 20
  - Phase Organization: (correctly phased / total) * 15

  IF quality score >= 90:
    Break from loop (phase complete)
  OTHERWISE:
    Document gaps and return to execution with refinements
```

## Phase 2: Validation & Output Generation

**Purpose**: Validate LLM-readiness and generate feature-developer.md compatible output with full context

### Activities

#### 1. Traceability Matrix Generation
```markdown
Build comprehensive traceability including existing coverage:

For each requirement:
  IF already satisfied:
    Reference existing task, Note as "Unchanged"
  ELSE IF modified:
    Reference modification task, Note as "Updated"
  ELSE:
    Reference new task, Note as "New"

Create delta-aware traceability matrix:
| Requirement | Tasks | Coverage | Status | Change Type |
|-------------|-------|----------|--------|-------------|
| REQ-001     | TASK-001 | 100%   | ‚úì   | Unchanged   |
| REQ-002     | TASK-002-mod | 100% | ‚úì  | Modified    |
| REQ-050     | TASK-050 | 100%   | ‚úì   | New         |
```

#### 2. Interface Validation
```markdown
Validate shared context and interface compatibility:
- Extract common patterns across tasks
- Document shared resources and interfaces
- Validate interface contract compatibility
- Validate shared constraints don't conflict
- Note integration points between tasks
```

#### 3. Critical Path Analysis
```markdown
Generate critical path:
- Identify longest dependency chain
- Mark parallel execution groups
- Note resource bottlenecks
- Validate no cycles remain after Phase 1 fixes
```

#### 4. Task File Generation
```markdown
For each task, create: task-NNN.md (or task-NNN-mod.md for modifications)

Task File Format:
---
task-id: TASK-NNN
title: [Clear outcome-focused title]
task-type: [new|modification|technical-update]
execution-phase: [0-setup|1-migration|2-feature-core|3-feature-ui|4-integration|5-validation|6-ci-cd]
complexity: [atomic|simple|moderate|complex]
parallel-eligible: [true|false]
source-requirements: [REQ-XXX, REQ-YYY]
source-use-cases: [UC-XXX, UC-YYY]
modifies: [TASK-XXX]  # Only for modifications
change-reason: [Use case change|Requirement change|Both]  # Only for modifications
dependencies: [TASK-XXX, TASK-YYY]
---

## Outcome Definition
[Clear, measurable outcome - what exists after completion]

## Change Context
[Only for modifications: What changed and why]
- Original: [What was implemented before]
- Change: [What needs to be different]
- Reason: [Use case evolution, requirement update, etc.]

## Definition of Ready
[From use case - conditions that must be met before starting]
- Technical prerequisites
- Knowledge requirements
- Resource availability
- Dependency completion

## Implementation Guidance
[From requirement - non-prescriptive approach]
### Approach
[High-level strategy without implementation details]

### Primary Flow
[Main steps to achieve outcome]

### Error Handling
[Failure modes to consider]

## Architectural Context
[From architecture.md - technology decisions and patterns]
### Technology Stack
[Relevant technology choices with rationale]

### Patterns to Apply
[Architectural patterns from architecture.md]

### MCP Tools Available
[From architecture.md - if MCP servers were discovered]
[List primary/secondary MCP server tools that can be used for this task]
[Example: mcp__gas__write for Code.gs files, mcp__gas__run for testing]

### Infrastructure State References

When generating this task file, examine <worktree>/planning/architecture.md for infrastructure state:

1. Look for section titled "## MCP Runtime State"
2. Look for section titled "## Service Runtime State"

IF either section exists in architecture.md THEN:
  Create subsection in this task documenting available state:

  **Available Infrastructure State**:

  For each state entry found, list in format:
  - {server/service-name}: {key}={value-from-architecture.md}

  Add usage guidance:
  "This state was created by Phase 0 initialization tasks. Reference these values
  in your implementation. For example, use scriptId when calling mcp__gas__write,
  or use connectionString when setting up database connections."

  Example output format:
  **MCP Runtime State**:
  - gas: scriptId=abc123xyz
  - github: repoUrl=https://github.com/user/repo

  **Service Runtime State**:
  - database: connectionString=postgresql://localhost:5432/mydb
  - storage: bucketName=my-app-uploads, region=us-east-1
  - auth: clientId=xyz789, domain=myapp.auth0.com

ELSE:
  Add note: "No infrastructure state available (Phase 0 initialization not needed for this project)"
END IF

**Note**: feature-developer.md will automatically provide architecture.md in the
implementation context, making all state readily accessible.

### Trade-offs Accepted
[Conscious decisions and their implications]

## Acceptance Criteria
[From requirement - testable conditions]
- [ ] Given [context], when [action], then [outcome]
- [ ] Performance: [specific metrics]
- [ ] Security: [specific requirements]
- [ ] Quality: [specific standards]

## Definition of Done
[From use case - completion checklist]
- User: [What user can do]
- System: [What system provides]
- Data: [What data exists]
- Quality: [What quality achieved]
- Security: [What security ensured]

## Testing Strategy
[From requirement - validation approach]
- Unit: [What to unit test]
- Integration: [What to integration test]
- Performance: [What to measure]
- User Acceptance: [What to validate]

## Notes for feature-developer.md
- All implementation details are your decision
- Reference architecture.md for technology guidance
- Maintain consistency with tasks in same phase
- Coordinate through defined interfaces
```

## GLOBAL END

**Execute ONCE after Phase 2 completion to finalize and validate**

### Global Quality Validation

```markdown
1. DELTA VALIDATION:
   For unchanged items: Verify correctly skipped
   For modified items: Verify modification task created
   For new items: Verify new task created

2. EVIDENCE GATHERING:
   For each requirement: Find implementing tasks, verify complexity scoring
   For each use case: Find implementing tasks, verify end-to-end coverage

3. GLOBAL QUALITY SCORE CALCULATION:
   GLOBAL_QUALITY_SCORE = (
     (DELTA_EFFICIENCY * 0.15) +            // Correctly skipped unchanged items
     (COMPLEXITY_APPROPRIATENESS * 0.15) +  // Tasks properly sized for LLMs
     (CONTEXT_COMPLETENESS * 0.20) +        // Rich context preserved
     (PHASE_ORGANIZATION * 0.15) +          // Correct execution sequencing
     (REQUIREMENT_COVERAGE * 0.15) +        // All changed requirements have tasks
     (USE_CASE_COVERAGE * 0.15) +          // All changed use cases traced
     (LLM_READINESS * 0.05)                // Guidance over prescription
   )

   MINIMUM_ACCEPTABLE_SCORE = 9.0/10.0

4. WORKTREE CONSOLIDATION (if created):
   IF <worktree_created> == true THEN:
     echo "üì¶ Consolidating results back to main environment"

     # Copy generated tasks to original location
     cp -r "<worktree>/planning/pending" "<original_pwd>/planning/pending"

     # Commit results in worktree
     git -C "<worktree>" add -A
     git -C "<worktree>" commit -m "Generated tasks from requirements"

     # Create patch for review
     git -C "<worktree>" format-patch -1 --stdout > "<original_pwd>/task-generation.patch"

     echo "‚úÖ Tasks generated and patch created for review"
   END IF

GLOBAL_END complete - task generation finalized
```

### Quality Assessment Thresholds

- **9.5-10.0**: Excellent - Ready for LLM execution
- **9.0-9.4**: Good - Minor context additions may help
- **8.0-8.9**: Acceptable - Some guidance gaps remain
- **Below 8.0**: Requires remediation

## Task Execution Sequencing

### Execution Phase Organization

```markdown
Generate execution phase flowchart showing LLM execution phases:

- **Phase 0 (Setup)**: One-time infrastructure, must complete first
- **Phase 1 (Migration)**: Data/schema changes, sequential within phase
- **Phase 2-3 (Features/UI)**: Parallel execution possible by multiple agents
- **Phase 4 (Integration)**: Requires feature completion, sequential
- **Phase 5 (Validation)**: Testing tasks, can parallelize by test type
- **Phase 6 (CI/CD)**: Final deployment preparation, sequential

Parallel execution opportunities: [Phase 2-3 tasks]
Critical path: [Phase 0 ‚Üí 1 ‚Üí 4 ‚Üí 5 ‚Üí 6]
Bottleneck phases: [Integration typically bottleneck]
LLM agent allocation: [Suggest agent-per-feature strategy]
```

## Return Summary

After completing both phases and global end, return concise summary:

```markdown
# Feature Task Generation Complete

## Summary
- **Tasks Generated**: [count] (new: [X], modifications: [Y])
- **Tasks Skipped**: [count] (unchanged items already satisfied)
- **Global Quality Score**: [X/10.0]
- **Delta Efficiency**: [X%] (correctly identified unchanged items)

## Coverage Analysis
- Total Use Cases: [X] ([Y] unchanged, [Z] changed/new)
- Total Requirements: [A] ([B] unchanged, [C] changed/new)
- Coverage: [100%] of changed items have implementing tasks

## Generated Task Files
- New Tasks: [task-050.md, task-051.md, ...]
- Modification Tasks: [task-001-mod.md, task-002-mod.md, ...]
- Files Location: `<worktree>/planning/pending/`

## Execution Phases
- Phase 0 (Setup): [X] tasks
- Phase 1 (Migration): [Y] tasks
- Phase 2-3 (Features): [Z] tasks (parallel eligible)
- Phase 4 (Integration): [A] tasks
- Phase 5 (Validation): [B] tasks
- Phase 6 (CI/CD): [C] tasks

## Next Steps
1. Review generated tasks in `<worktree>/planning/pending/`
2. Execute tasks via feature-developer agent in phase order
3. Use parallel execution for Phase 2-3 tasks when possible
4. Follow critical path: Setup ‚Üí Migration ‚Üí Features ‚Üí Integration ‚Üí Validation ‚Üí CI/CD

## Efficiency Metrics
- Reuse Rate: [X%] of requirements already satisfied
- Delta Accuracy: [Y%] correctly identified as unchanged
- Generation Efficiency: Only [Z%] of total items needed new tasks

The complete task decomposition with delta detection has generated only the necessary tasks while preserving full context for LLM execution.
```

Execute systematically, detect changes accurately, decompose intelligently, preserve context completely.